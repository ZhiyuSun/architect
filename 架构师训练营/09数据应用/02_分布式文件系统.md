# 数据应用

## 分布式文件系统

### HDFS系统架构

### HDFS设计目标

HDFS 以流式数据访问模式存储超大文件，运行于商用硬件集群上。
超大文件
流式数据访问
- 一次写入多次读取
商用硬件

### 不适合HDFS 的场景
低延迟的数据访问
大量小文件
- 超过NameNode 的处理能力
多用户随机写入修改文件

HDFS 为了做到可靠性（reliability）创建了多份数据块（data blocks）的复制（replicas），并将它们放置在服务器群的计算节点中（compute nodes），MapReduce 就可以在它们所在的节点上处理这些数据了。

### 设计目标

假设：节点失效是常态
理想：
1. 任何一个节点失效，不影响HDFS 服务
2. HDFS 可以自动完成副本的复制

### 文件

文件切分成块（默认大小64M），以块为单位，每个块有多个副本存储在不同的机器上，副本数可在文件生成时指定（默认3）

NameNode 是主节点，存储文件的元数据如文件名，文件目录结构，文件属性（生成时间,副本数,文件权限），以及每个文件的块列表以及块所在的DataNode 等等

DataNode 在本地文件系统存储文件块数据，以及块数据的校验和可以创建、删除、移动或重命名文件，当文件创建、写入和关闭之后不能修改文件内容。




