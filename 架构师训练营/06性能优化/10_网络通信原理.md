# 性能优化

## 网络通信

### web请求一次的网络通信历程

### OSI七层模型和TCP/IP四层模型

应用层，表示层，会话层——应用层
传输层——传输层：提供端对端的接口
网络层——网络互联层：为数据包选择路由
数据链路层，物理层——网络访问层：传输有地址的帧一级错误检测功能。在物理没接上传输二进制格式数据

### 网络数据包格式

HTTP协议头，TCP协议头，IP协议头，链路层协议头

### 物理层

物理层负责数据的物理传输，计算机输入输出的只能是0 1 这样的二进制数据，但是在真正的通信线路里有光纤、电缆、无线各种设备。光信号和电信号，以及无线电磁信号在物理上是完全不同的，如何让这些不同的设备能够理解、处理相同的二进制数据，这就是物理层要解决的问题。

### 链路层

链路层就是将数据进行封装后交给物理层进行传输，主要就是将数据封装成数据帧，以帧为单位通过物理层进行通信，有了帧，就可以在帧上进行数据校验，进行流量控制。

链路层会定义帧的大小，这个大小也被称为最大传输单元。像HTTP 要在传输的数据上添加一个HTTP 头一样，数据链路层也会将封装好的帧添加一个帧头，帧头里记录的一个重要信息就是发送者和接受者的MAC 地址。MAC 地址是网卡的设备标识符，是唯一的，数据帧通过这个信息确保数据送达到正确的目标机器。

### 网络层

网络层IP 协议使得互联网应用根据IP 地址就能访问到目标服务器，请求离开App 后，到达运营服务商的交换机，交换机会根据这个IP 地址进行路由转发，可能中间会经过很多个转发节点，最后数据到达目标服务器。

网络层的数据需要交给链路层进行处理，而链路层帧的大小定义了最大传输单元，网络层的IP 数据包必须要小于最大传输单元才能进行网络传输，这个数据包也有一个IP 头，主要包括的就是发送者和接受者的IP 地址。

IP负载均衡

### 传输层（TCP协议）

IP 协议不是一个可靠的通信协议，不会建立稳定的通信链路，并不会确保数据一定送达。要保证通信的稳定可靠，需要传输层协议TCP。

TCP协议是一种面向连接的、可靠的、基于字节流的传输层协议。TCP作为一个比较基础的通讯协议，有很多重要的机制保证了TCP协议的可靠性和强壮性：

使用序号，对收到的TCP报文段进行排序和检测重复的数据
无错传输，使用校验和检测报文段的错误
使用确认和计时器来检测和纠正丢包或者延时
流量控制，避免主机分组发送得过快而使接收方来不及完全收下
拥塞控制，发送方根据网络承载情况控制分组的发送量，以获得高性能同时避免拥塞崩溃丢失包的重传

TCP 建立连接的3次握手过程
1. App 先发送SYN=1，Seq=X 的报文，表示请求建立连接，X 是一个随机数；
2. 服务器收到这个报文后，应答SYN=1，ACK=X+1，Seq=Y 的报文，表示同意建立连接；
3. App 收到这个报文后，检查ACK 的值为自己发送的Seq 值+1，确认建立连接，并发送ACK=Y+1 的报文给服务器；服务器收到这个报文后检查ACK 值为自己发送的Seq值+1，确认建立连接。至此，App 和服务器建立起TCP 连接，就可以进行数据传输了。

TCP 关闭连接4次挥手
• 客户端向服务器端发送一个FIN，请求关闭数据传输。
• 当服务器接收到客户端的FIN 时，向客户端发送一个ACK，其中ACK 的值等于FIN + SEQ。
• 然后服务器向客户端发送一个FIN，告诉客户端应用程序关闭。
• 当客户端收到服务器端的FIN 是，回复一个ACK 给服务器端。其中ACK 的值等于FIN + SEQ。

### 应用层HTTP协议

而互联网应用需要在全球范围为用户提供服务，将全球的应用和全球的用户联系在一起，需要一个统一的应用层协议，这个协议就是HTTP 协议。

### HTTP请求的7中方法

Get：只读请求，请求处理过程不应该产生副作用，即web应用不应该因为get 请求而发生任何状态改变。
Head：和get 方法一样，但是只返回响应头。
Post：提交请求。
Put：上传请求。
Delete：删除URL 标识的资源。
Trace：回显服务器收到的请求，用以测试或者诊断。
Options：请求服务器返回支持的所有HTTP 请求方法，测试服务器是否正常。

### HTTP响应的5种状态

1xx消息——请求已被服务器接收，继续处理
2xx成功——请求已成功被服务器接收、理解、并接受
3xx重定向——需要后续操作才能完成这一请求
4xx请求错误——请求含有词法错误或者无法被执行
5xx服务器错误——服务器在处理某个正确请求时发生错误

### HTTP协议版本

1996 年发布了HTTP/1.0 ，在HTTP/1.0 中，客户端和服务器之间交换的每个请求/ 响应都会创建一个新的TCP 连接，这意味着所
有请求之前都需要进行TCP握手连接，因此所有请求都会产生延迟。

HTTP/1.1 试图引入保持连接的概念来解决这些问题，它允许客户端复用TCP 连接，从而分摊了建立初始连接和针对多个请求缓慢启动的成本。但任意时点上每个连接只能执行一次请求/ 响应交换。

随着网络的发展，网站所需资源（CSS、JavaScript 和图像等）不断增长，浏览器在获取和呈现网页时需要越来越多的并发性。但由于HTTP/1.1 只允许客户端同时进行一次HTTP 请求/ 响应交换，因此在网络层上获得并发能力的唯一方法是并行使用多个TCP连接。

HTTP/2 引入了HTTP“流”的概念，允许将不同的HTTP 并发地复用到同一TCP 连接上， 使浏览器更高效地复用TCP 连接。HTTP/2 解决了单个TCP 连接的使用效率低的问题，现在可以通过同一连接同时传输多个请求/ 响应。但是，TCP并不理解HTTP流，当多个HTTP请求复用一个TCP连接，如果前面的请求/响应没有处理完，后面的请求/响应也无法处理，也就是会出现队头堵塞现象。

HTTP/3 不是使用TCP 作为会话的传输层，而是使用QUIC （一种新的互联网传输协议）。该协议在传输层将流作为一等公民引入。多个
QUIC 流共享相同的QUIC 连接，因此不需要额外的握手和慢启动来创建新的QUIC 流。但QUIC 流是独立的，因此在大多数情况下，只
影响一个流的丢包不会影响其他流，这是因为QUIC 数据包封装在UDP数据包。